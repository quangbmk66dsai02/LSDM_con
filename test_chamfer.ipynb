{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def timestep_embedding(timesteps, dim, max_period=10000):\n",
    "    \"\"\"\n",
    "    Create sinusoidal timestep embeddings.\n",
    "\n",
    "    :param timesteps: a 1-D Tensor of N indices, one per batch element.\n",
    "                      These may be fractional.\n",
    "    :param dim: the dimension of the output.\n",
    "    :param max_period: controls the minimum frequency of the embeddings.\n",
    "    :return: an [N x dim] Tensor of positional embeddings.\n",
    "    \"\"\"\n",
    "    # Initialize the positional encodings tensor\n",
    "    pe = torch.zeros(timesteps.size(0), dim, device=timesteps.device)\n",
    "    \n",
    "    # Create a tensor of positions (0, 1, 2, ..., timesteps.size(0)-1)\n",
    "    position = timesteps.unsqueeze(1).float()\n",
    "\n",
    "    # Create a tensor of scaling factors\n",
    "    div_term = torch.exp(torch.arange(0, dim, 2, dtype=torch.float, device=timesteps.device) * (-math.log(max_period) / dim))\n",
    "\n",
    "    # Apply sine to even indices\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "    # Apply cosine to odd indices\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    return pe\n",
    "\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    def __init__(self, latent_dim, max_period=10000, device=None):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.max_period = max_period\n",
    "\n",
    "        time_embed_dim = self.latent_dim\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embed_dim, time_embed_dim),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, timesteps):\n",
    "        if not isinstance(timesteps, torch.Tensor):\n",
    "            timesteps = torch.tensor(timesteps, dtype=torch.float).to(self.time_embed[0].weight.device)\n",
    "        else:\n",
    "            timesteps = timesteps.float().to(self.time_embed[0].weight.device)\n",
    "        \n",
    "        encodings = timestep_embedding(timesteps, self.latent_dim, self.max_period)\n",
    "        dense_encodings = encodings.unsqueeze(0)  # Add an extra dimension\n",
    "        return self.time_embed(dense_encodings).permute(1, 0, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1014,  0.0478,  0.0693, -0.1509, -0.0652,  0.0832, -0.1776,\n",
      "          -0.1637, -0.0710, -0.0984, -0.2567,  0.1436, -0.2774,  0.2691,\n",
      "          -0.0472, -0.1858, -0.0243,  0.0800,  0.2080,  0.2286, -0.1796,\n",
      "           0.0021, -0.0815, -0.0229, -0.0348,  0.1422,  0.2072, -0.0084,\n",
      "          -0.1027,  0.0097, -0.0389,  0.1433, -0.0008, -0.1679,  0.0298,\n",
      "           0.2263, -0.0890, -0.0814,  0.0503, -0.0630,  0.1955, -0.2240,\n",
      "          -0.2530, -0.0710, -0.0109, -0.0217,  0.1262, -0.1919,  0.0059,\n",
      "          -0.0572, -0.0775, -0.0460, -0.0400, -0.1212,  0.0152,  0.0717,\n",
      "           0.0334, -0.0348, -0.1932,  0.0103, -0.0496, -0.0836,  0.2242,\n",
      "          -0.0530, -0.1115,  0.0179, -0.2222, -0.0946, -0.0136, -0.0535,\n",
      "          -0.0059,  0.0627,  0.0156, -0.1373,  0.0382, -0.0188,  0.0893,\n",
      "           0.0682, -0.0940, -0.0601,  0.1521, -0.0607,  0.0450,  0.1164,\n",
      "           0.1199,  0.1075, -0.1289, -0.0208, -0.0291,  0.0644,  0.0605,\n",
      "           0.1385, -0.1831,  0.1386,  0.0336, -0.0306, -0.3263, -0.0098,\n",
      "           0.1062,  0.1145, -0.0948, -0.1696, -0.0405,  0.0190, -0.1868,\n",
      "           0.2305,  0.0424, -0.3329,  0.0890,  0.2089,  0.0483, -0.0331,\n",
      "          -0.1308,  0.2449, -0.0605,  0.0068, -0.0213, -0.1440, -0.0230,\n",
      "           0.0626, -0.0934, -0.2269, -0.1698,  0.0807, -0.0376, -0.0504,\n",
      "           0.0501,  0.0089]]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "latent_dim = 128\n",
    "ts = 10  # Example timestep\n",
    "\n",
    "# Create TimestepEmbedder instance\n",
    "embed_timestep = TimestepEmbedder(latent_dim, device=device)\n",
    "\n",
    "# Get the embeddings for the given timesteps\n",
    "timesteps = torch.tensor([ts], dtype=torch.float).to(device)\n",
    "embeddings = embed_timestep(timesteps)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the fwd of TE tensor([10])\n",
      "this is the pe of len 5000 \n",
      " tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
      "           0.0000e+00,  1.0000e+00]],\n",
      "\n",
      "        [[ 8.4147e-01,  5.4030e-01,  7.6172e-01,  ...,  1.0000e+00,\n",
      "           1.1548e-04,  1.0000e+00]],\n",
      "\n",
      "        [[ 9.0930e-01, -4.1615e-01,  9.8705e-01,  ...,  1.0000e+00,\n",
      "           2.3096e-04,  1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 9.5625e-01, -2.9254e-01, -9.4916e-01,  ...,  7.8608e-01,\n",
      "           5.4555e-01,  8.3808e-01]],\n",
      "\n",
      "        [[ 2.7050e-01, -9.6272e-01, -8.5488e-01,  ...,  7.8599e-01,\n",
      "           5.4565e-01,  8.3802e-01]],\n",
      "\n",
      "        [[-6.6395e-01, -7.4778e-01, -1.5844e-01,  ...,  7.8591e-01,\n",
      "           5.4574e-01,  8.3795e-01]]])\n",
      "this is the encoded with PE\n",
      " tensor([[[-0.5440, -0.8391,  0.6926, -0.7213,  0.9376,  0.3476,  0.2091,\n",
      "           0.9779, -0.6129,  0.7901, -0.9877,  0.1566, -0.8798, -0.4754,\n",
      "          -0.4883, -0.8727, -0.0207, -0.9998,  0.3923, -0.9198,  0.6963,\n",
      "          -0.7178,  0.8857, -0.4642,  0.9786, -0.2060,  0.9995,  0.0309,\n",
      "           0.9720,  0.2351,  0.9147,  0.4041,  0.8415,  0.5403,  0.7617,\n",
      "           0.6479,  0.6816,  0.7318,  0.6047,  0.7965,  0.5332,  0.8460,\n",
      "           0.4679,  0.8838,  0.4093,  0.9124,  0.3571,  0.9341,  0.3110,\n",
      "           0.9504,  0.2704,  0.9627,  0.2349,  0.9720,  0.2039,  0.9790,\n",
      "           0.1769,  0.9842,  0.1534,  0.9882,  0.1330,  0.9911,  0.1152,\n",
      "           0.9933,  0.0998,  0.9950,  0.0865,  0.9963,  0.0749,  0.9972,\n",
      "           0.0649,  0.9979,  0.0562,  0.9984,  0.0487,  0.9988,  0.0422,\n",
      "           0.9991,  0.0365,  0.9993,  0.0316,  0.9995,  0.0274,  0.9996,\n",
      "           0.0237,  0.9997,  0.0205,  0.9998,  0.0178,  0.9998,  0.0154,\n",
      "           0.9999,  0.0133,  0.9999,  0.0115,  0.9999,  0.0100,  0.9999,\n",
      "           0.0087,  1.0000,  0.0075,  1.0000,  0.0065,  1.0000,  0.0056,\n",
      "           1.0000,  0.0049,  1.0000,  0.0042,  1.0000,  0.0037,  1.0000,\n",
      "           0.0032,  1.0000,  0.0027,  1.0000,  0.0024,  1.0000,  0.0021,\n",
      "           1.0000,  0.0018,  1.0000,  0.0015,  1.0000,  0.0013,  1.0000,\n",
      "           0.0012,  1.0000]]])\n",
      "done pos_encoding\n",
      "tensor([[[ 0.0033,  0.0737,  0.0600, -0.2251,  0.1077,  0.1952,  0.0727,\n",
      "          -0.0330, -0.0564,  0.1810,  0.0503,  0.1027, -0.1519, -0.1162,\n",
      "          -0.0990,  0.1030, -0.0801,  0.1334, -0.1624,  0.1924, -0.1143,\n",
      "          -0.1085,  0.0260, -0.2577,  0.1549, -0.0542,  0.2056, -0.0051,\n",
      "           0.1210,  0.1166,  0.1181,  0.2968, -0.0061, -0.0195, -0.1038,\n",
      "          -0.0532, -0.0082,  0.1598, -0.3453, -0.1529, -0.1200,  0.0649,\n",
      "           0.2947,  0.1508,  0.0296,  0.0221,  0.1787,  0.1550, -0.0311,\n",
      "          -0.0067, -0.1588,  0.0942, -0.0630,  0.0032,  0.0757,  0.1916,\n",
      "           0.0939,  0.0462,  0.0543, -0.0803,  0.1317, -0.1128, -0.2462,\n",
      "          -0.0377, -0.2631,  0.1939,  0.1072,  0.0688, -0.1354, -0.0140,\n",
      "          -0.2194, -0.0781,  0.0918, -0.0304,  0.0254, -0.0903, -0.1328,\n",
      "          -0.1521, -0.0578, -0.1710, -0.0609,  0.0609,  0.1196, -0.1208,\n",
      "          -0.0082, -0.0533,  0.0122, -0.1012, -0.0619, -0.0271,  0.1100,\n",
      "           0.2088, -0.1962, -0.1791, -0.0222,  0.0666,  0.0019, -0.0435,\n",
      "          -0.0520,  0.1260, -0.0175,  0.0962,  0.1503,  0.0895,  0.1394,\n",
      "          -0.1355, -0.3128,  0.0487,  0.0449,  0.1983,  0.2035, -0.0776,\n",
      "           0.0722,  0.0976, -0.3115, -0.2339,  0.2186, -0.1438,  0.1420,\n",
      "          -0.0594,  0.2560, -0.0711, -0.0688, -0.1256, -0.0907,  0.0854,\n",
      "          -0.0182,  0.1171]]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from model.diffusion_utils import *\n",
    "\n",
    "ts = 10  # Example timestep\n",
    "\n",
    "dropout = 0.1\n",
    "latent_dim = 128\n",
    "sequence_pos_encoder = PositionalEncoding(latent_dim, dropout, device=\"cpu\")\n",
    "embed_timestep = TimestepEmbedder(latent_dim, sequence_pos_encoder, device='cpu')\n",
    "\n",
    "timesteps = torch.tensor([ts], dtype=torch.float).to(device)\n",
    "timesteps = timesteps.long()\n",
    "print(embed_timestep(timesteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5440, -0.8391,  0.6926, -0.7213,  0.9376,  0.3476,  0.2091,\n",
       "           0.9779, -0.6129,  0.7901, -0.9877,  0.1566, -0.8798, -0.4754,\n",
       "          -0.4883, -0.8727, -0.0207, -0.9998,  0.3923, -0.9198,  0.6963,\n",
       "          -0.7178,  0.8857, -0.4642,  0.9786, -0.2060,  0.9995,  0.0309,\n",
       "           0.9720,  0.2351,  0.9147,  0.4041,  0.8415,  0.5403,  0.7617,\n",
       "           0.6479,  0.6816,  0.7318,  0.6047,  0.7965,  0.5332,  0.8460,\n",
       "           0.4679,  0.8838,  0.4093,  0.9124,  0.3571,  0.9341,  0.3110,\n",
       "           0.9504,  0.2704,  0.9627,  0.2349,  0.9720,  0.2039,  0.9790,\n",
       "           0.1769,  0.9842,  0.1534,  0.9882,  0.1330,  0.9911,  0.1152,\n",
       "           0.9933,  0.0998,  0.9950,  0.0865,  0.9963,  0.0749,  0.9972,\n",
       "           0.0649,  0.9979,  0.0562,  0.9984,  0.0487,  0.9988,  0.0422,\n",
       "           0.9991,  0.0365,  0.9993,  0.0316,  0.9995,  0.0274,  0.9996,\n",
       "           0.0237,  0.9997,  0.0205,  0.9998,  0.0178,  0.9998,  0.0154,\n",
       "           0.9999,  0.0133,  0.9999,  0.0115,  0.9999,  0.0100,  0.9999,\n",
       "           0.0087,  1.0000,  0.0075,  1.0000,  0.0065,  1.0000,  0.0056,\n",
       "           1.0000,  0.0049,  1.0000,  0.0042,  1.0000,  0.0037,  1.0000,\n",
       "           0.0032,  1.0000,  0.0027,  1.0000,  0.0024,  1.0000,  0.0021,\n",
       "           1.0000,  0.0018,  1.0000,  0.0015,  1.0000,  0.0013,  1.0000,\n",
       "           0.0012,  1.0000]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create TimestepEmbedder instance\n",
    "\n",
    "# Get the embeddings for the given timesteps\n",
    "timesteps = torch.tensor([ts], dtype=torch.float).to(device)\n",
    "timesteps = timesteps.long()\n",
    "print(timesteps)\n",
    "ori_pe = PositionalEncoding(d_model = 128, dropout=0.1, max_len=10000, device=\"cpu\")\n",
    "ori_pe.pe[timesteps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5440, -0.8391,  0.6926, -0.7213,  0.9376,  0.3476,  0.2091,  0.9779,\n",
      "         -0.6129,  0.7901, -0.9877,  0.1566, -0.8798, -0.4754, -0.4883, -0.8727,\n",
      "         -0.0207, -0.9998,  0.3923, -0.9198,  0.6963, -0.7178,  0.8857, -0.4642,\n",
      "          0.9786, -0.2060,  0.9995,  0.0309,  0.9720,  0.2351,  0.9147,  0.4041,\n",
      "          0.8415,  0.5403,  0.7617,  0.6479,  0.6816,  0.7318,  0.6047,  0.7965,\n",
      "          0.5332,  0.8460,  0.4679,  0.8838,  0.4093,  0.9124,  0.3571,  0.9341,\n",
      "          0.3110,  0.9504,  0.2704,  0.9627,  0.2349,  0.9720,  0.2039,  0.9790,\n",
      "          0.1769,  0.9842,  0.1534,  0.9882,  0.1330,  0.9911,  0.1152,  0.9933,\n",
      "          0.0998,  0.9950,  0.0865,  0.9963,  0.0749,  0.9972,  0.0649,  0.9979,\n",
      "          0.0562,  0.9984,  0.0487,  0.9988,  0.0422,  0.9991,  0.0365,  0.9993,\n",
      "          0.0316,  0.9995,  0.0274,  0.9996,  0.0237,  0.9997,  0.0205,  0.9998,\n",
      "          0.0178,  0.9998,  0.0154,  0.9999,  0.0133,  0.9999,  0.0115,  0.9999,\n",
      "          0.0100,  0.9999,  0.0087,  1.0000,  0.0075,  1.0000,  0.0065,  1.0000,\n",
      "          0.0056,  1.0000,  0.0049,  1.0000,  0.0042,  1.0000,  0.0037,  1.0000,\n",
      "          0.0032,  1.0000,  0.0027,  1.0000,  0.0024,  1.0000,  0.0021,  1.0000,\n",
      "          0.0018,  1.0000,  0.0015,  1.0000,  0.0013,  1.0000,  0.0012,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def timestep_embedding(timesteps, dim, max_period=10000):\n",
    "    \"\"\"\n",
    "    Create sinusoidal timestep embeddings.\n",
    "\n",
    "    :param timesteps: a 1-D Tensor of N indices, one per batch element.\n",
    "                      These may be fractional.\n",
    "    :param dim: the dimension of the output.\n",
    "    :param max_period: controls the minimum frequency of the embeddings.\n",
    "    :return: an [N x dim] Tensor of positional embeddings.\n",
    "    \"\"\"\n",
    "    # Initialize the positional encodings tensor\n",
    "    pe = torch.zeros(timesteps.size(0), dim, device=timesteps.device)\n",
    "    \n",
    "    # Create a tensor of positions (0, 1, 2, ..., timesteps.size(0)-1)\n",
    "    position = timesteps.unsqueeze(1).float()\n",
    "\n",
    "    # Create a tensor of scaling factors\n",
    "    div_term = torch.exp(torch.arange(0, dim, 2, dtype=torch.float, device=timesteps.device) * (-math.log(max_period) / dim))\n",
    "\n",
    "    # Apply sine to even indices\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "    # Apply cosine to odd indices\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    return pe\n",
    "timesteps = torch.tensor([ts], dtype=torch.float).to(device)\n",
    "timesteps = timesteps.long()\n",
    "# Example usage\n",
    "dim = 128\n",
    "embeddings = timestep_embedding(timesteps, dim)\n",
    "print(embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
